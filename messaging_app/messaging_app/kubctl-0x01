#!/bin/bash

# kubctl-0x01 - Kubernetes Application Scaling Script
# File: messaging_app/kubctl-0x01
# Repository: alx-backend-python

set -e  # Exit on any error

# Colors for output
RED='\033[0;31m'
GREEN='\033[0;32m'
YELLOW='\033[1;33m'
BLUE='\033[0;34m'
CYAN='\033[0;36m'
NC='\033[0m' # No Color

# Configuration
DEPLOYMENT_NAME="django-messaging-app"
SERVICE_NAME="django-messaging-service"
TARGET_REPLICAS=3
LOAD_TEST_DURATION="30s"
LOAD_TEST_CONNECTIONS=10
LOAD_TEST_THREADS=2

# Function to print colored output
print_status() {
    echo -e "${BLUE}[INFO]${NC} $1"
}

print_success() {
    echo -e "${GREEN}[SUCCESS]${NC} $1"
}

print_warning() {
    echo -e "${YELLOW}[WARNING]${NC} $1"
}

print_error() {
    echo -e "${RED}[ERROR]${NC} $1"
}

print_header() {
    echo -e "${CYAN}========================================${NC}"
    echo -e "${CYAN} $1${NC}"
    echo -e "${CYAN}========================================${NC}"
}

# Function to check if command exists
command_exists() {
    command -v "$1" >/dev/null 2>&1
}

# Function to check prerequisites
check_prerequisites() {
    print_header "Checking Prerequisites"
    
    # Check kubectl
    if ! command_exists kubectl; then
        print_error "kubectl is not installed or not in PATH"
        exit 1
    fi
    print_success "kubectl is available"
    
    # Check if cluster is accessible
    if ! kubectl cluster-info >/dev/null 2>&1; then
        print_error "Cannot connect to Kubernetes cluster"
        print_status "Make sure your cluster is running (minikube start)"
        exit 1
    fi
    print_success "Kubernetes cluster is accessible"
    
    # Check if deployment exists
    if ! kubectl get deployment "$DEPLOYMENT_NAME" >/dev/null 2>&1; then
        print_error "Deployment '$DEPLOYMENT_NAME' not found"
        print_status "Make sure you've deployed your Django app first"
        exit 1
    fi
    print_success "Deployment '$DEPLOYMENT_NAME' found"
    
    # Check wrk for load testing
    if ! command_exists wrk; then
        print_warning "wrk is not installed. Will attempt to install it..."
        install_wrk
    else
        print_success "wrk is available for load testing"
    fi
}

# Function to install wrk
install_wrk() {
    print_status "Installing wrk..."
    
    if [[ "$OSTYPE" == "linux-gnu"* ]]; then
        # Linux
        if command_exists apt-get; then
            sudo apt-get update && sudo apt-get install -y wrk
        elif command_exists yum; then
            sudo yum install -y wrk
        else
            print_error "Cannot install wrk automatically on this system"
            print_status "Please install wrk manually: https://github.com/wg/wrk"
            exit 1
        fi
    elif [[ "$OSTYPE" == "darwin"* ]]; then
        # macOS
        if command_exists brew; then
            brew install wrk
        else
            print_error "Homebrew not found. Please install wrk manually"
            exit 1
        fi
    elif [[ "$OSTYPE" == "msys" ]] || [[ "$OSTYPE" == "cygwin" ]]; then
        # Windows (Git Bash/Cygwin)
        print_error "wrk installation on Windows requires manual setup"
        print_status "Please install wrk from: https://github.com/wg/wrk/releases"
        print_status "Alternative: Use WSL or install via package manager"
        exit 1
    else
        print_error "Unsupported operating system for automatic wrk installation"
        exit 1
    fi
    
    if command_exists wrk; then
        print_success "wrk installed successfully"
    else
        print_error "Failed to install wrk"
        exit 1
    fi
}

# Function to scale deployment
scale_deployment() {
    print_header "Scaling Deployment"
    
    print_status "Current deployment status:"
    kubectl get deployment "$DEPLOYMENT_NAME"
    
    print_status "Scaling deployment to $TARGET_REPLICAS replicas..."
    kubectl scale deployment "$DEPLOYMENT_NAME" --replicas="$TARGET_REPLICAS"
    
    print_status "Waiting for rollout to complete..."
    kubectl rollout status deployment/"$DEPLOYMENT_NAME" --timeout=300s
    
    print_success "Deployment scaled successfully!"
}

# Function to verify pods are running
verify_pods() {
    print_header "Verifying Pod Status"
    
    print_status "Checking pod status..."
    kubectl get pods -l app="$DEPLOYMENT_NAME"
    
    # Wait for all pods to be ready
    print_status "Waiting for all pods to be ready..."
    kubectl wait --for=condition=ready pod -l app="$DEPLOYMENT_NAME" --timeout=300s
    
    # Count running pods
    RUNNING_PODS=$(kubectl get pods -l app="$DEPLOYMENT_NAME" --field-selector=status.phase=Running --no-headers | wc -l)
    
    if [ "$RUNNING_PODS" -eq "$TARGET_REPLICAS" ]; then
        print_success "All $TARGET_REPLICAS pods are running successfully!"
    else
        print_warning "Expected $TARGET_REPLICAS pods, but found $RUNNING_PODS running"
    fi
    
    echo ""
    print_status "Detailed pod information:"
    kubectl get pods -l app="$DEPLOYMENT_NAME" -o wide
}

# Function to get service URL for load testing
get_service_url() {
    print_status "Getting service URL..."
    
    # Check if service exists
    if ! kubectl get service "$SERVICE_NAME" >/dev/null 2>&1; then
        print_error "Service '$SERVICE_NAME' not found"
        return 1
    fi
    
    # Get service type
    SERVICE_TYPE=$(kubectl get service "$SERVICE_NAME" -o jsonpath='{.spec.type}')
    
    if [ "$SERVICE_TYPE" = "NodePort" ]; then
        # For NodePort services
        if command_exists minikube; then
            SERVICE_URL=$(minikube service "$SERVICE_NAME" --url)
        else
            NODE_PORT=$(kubectl get service "$SERVICE_NAME" -o jsonpath='{.spec.ports[0].nodePort}')
            NODE_IP=$(kubectl get nodes -o jsonpath='{.items[0].status.addresses[0].address}')
            SERVICE_URL="http://${NODE_IP}:${NODE_PORT}"
        fi
    elif [ "$SERVICE_TYPE" = "LoadBalancer" ]; then
        # For LoadBalancer services
        EXTERNAL_IP=$(kubectl get service "$SERVICE_NAME" -o jsonpath='{.status.loadBalancer.ingress[0].ip}')
        SERVICE_PORT=$(kubectl get service "$SERVICE_NAME" -o jsonpath='{.spec.ports[0].port}')
        SERVICE_URL="http://${EXTERNAL_IP}:${SERVICE_PORT}"
    else
        # For ClusterIP services, use port forwarding
        print_status "Service is ClusterIP type. Setting up port forwarding..."
        kubectl port-forward service/"$SERVICE_NAME" 8080:80 &
        PORT_FORWARD_PID=$!
        sleep 5  # Wait for port forward to establish
        SERVICE_URL="http://localhost:8080"
    fi
    
    echo "$SERVICE_URL"
}

# Function to perform load testing
perform_load_testing() {
    print_header "Load Testing"
    
    SERVICE_URL=$(get_service_url)
    
    if [ -z "$SERVICE_URL" ]; then
        print_error "Could not determine service URL"
        return 1
    fi
    
    print_status "Service URL: $SERVICE_URL"
    
    # Test if service is accessible
    print_status "Testing service accessibility..."
    if command_exists curl; then
        if curl -s --max-time 10 "$SERVICE_URL" >/dev/null; then
            print_success "Service is accessible"
        else
            print_warning "Service might not be fully ready. Continuing with load test..."
        fi
    fi
    
    print_status "Starting load test..."
    print_status "Duration: $LOAD_TEST_DURATION"
    print_status "Connections: $LOAD_TEST_CONNECTIONS"
    print_status "Threads: $LOAD_TEST_THREADS"
    
    echo ""
    wrk -t"$LOAD_TEST_THREADS" -c"$LOAD_TEST_CONNECTIONS" -d"$LOAD_TEST_DURATION" --timeout=30s "$SERVICE_URL"
    
    print_success "Load testing completed!"
    
    # Clean up port forward if it was used
    if [ -n "$PORT_FORWARD_PID" ]; then
        kill $PORT_FORWARD_PID 2>/dev/null || true
        print_status "Cleaned up port forwarding"
    fi
}

# Function to monitor resource usage
monitor_resources() {
    print_header "Resource Monitoring"
    
    # Check if metrics server is available
    if ! kubectl top nodes >/dev/null 2>&1; then
        print_warning "Metrics server not available. Installing metrics server..."
        install_metrics_server
    fi
    
    print_status "Node resource usage:"
    kubectl top nodes
    
    echo ""
    print_status "Pod resource usage:"
    kubectl top pods -l app="$DEPLOYMENT_NAME"
    
    echo ""
    print_status "Deployment resource limits and requests:"
    kubectl describe deployment "$DEPLOYMENT_NAME" | grep -A 10 "Limits\|Requests" || true
    
    echo ""
    print_status "Pod events (last 10):"
    kubectl get events --field-selector involvedObject.kind=Pod --sort-by='.lastTimestamp' | tail -10
}

# Function to install metrics server (for minikube)
install_metrics_server() {
    if command_exists minikube; then
        print_status "Enabling metrics server in minikube..."
        minikube addons enable metrics-server
        
        print_status "Waiting for metrics server to be ready..."
        sleep 30
        
        # Wait for metrics server to be available
        for i in {1..30}; do
            if kubectl top nodes >/dev/null 2>&1; then
                print_success "Metrics server is ready"
                return 0
            fi
            sleep 10
        done
        
        print_warning "Metrics server may not be fully ready yet"
    else
        print_warning "Not using minikube. Please ensure metrics server is installed"
    fi
}

# Function to display scaling summary
show_summary() {
    print_header "Scaling Summary"
    
    echo ""
    print_status "Final deployment status:"
    kubectl get deployment "$DEPLOYMENT_NAME"
    
    echo ""
    print_status "Final pod status:"
    kubectl get pods -l app="$DEPLOYMENT_NAME"
    
    echo ""
    print_status "Service information:"
    kubectl get service "$SERVICE_NAME"
    
    echo ""
    print_success "Scaling operation completed successfully!"
    
    echo ""
    print_status "Useful commands for ongoing monitoring:"
    echo "â€¢ Watch pods: kubectl get pods -l app=$DEPLOYMENT_NAME -w"
    echo "â€¢ Monitor resources: kubectl top pods -l app=$DEPLOYMENT_NAME"
    echo "â€¢ Scale further: kubectl scale deployment $DEPLOYMENT_NAME --replicas=<number>"
    echo "â€¢ Check logs: kubectl logs -l app=$DEPLOYMENT_NAME --tail=50"
    echo "â€¢ Rollout status: kubectl rollout status deployment/$DEPLOYMENT_NAME"
}

# Main execution function
main() {
    print_header "Kubernetes Application Scaling"
    
    # Step 1: Check prerequisites
    check_prerequisites
    
    # Step 2: Scale deployment using kubectl scale
    scale_deployment
    
    # Step 3: Verify pods are running using kubectl get pods
    verify_pods
    
    # Step 4: Perform load testing using wrk
    perform_load_testing
    
    # Step 5: Monitor resource usage using kubectl top
    monitor_resources
    
    # Step 6: Show summary
    show_summary
}

# Error handling
trap 'print_error "Script failed at line $LINENO"' ERR

# Cleanup function
cleanup() {
    if [ -n "$PORT_FORWARD_PID" ]; then
        kill $PORT_FORWARD_PID 2>/dev/null || true
    fi
}
trap cleanup EXIT

# Run main function
main "$@"